{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cognitive-explanation",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "# About data cleaning for own language \n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- **The goal of this lab is to go through some basic data cleansing methods which should be cautiously applied to own langauge dataset  **\n",
    "    - langauge detection and filtering \n",
    "    - finding sentence boundary, and give some examples :\n",
    "    it is importance to be able to find good sentence boundary per given document, see [Megatron-LM/tools/preprocess_data.py](https://github.com/NVIDIA/Megatron-LM/blob/main/tools/preprocess_data.py#L84)\n",
    "        1. [sentence-splitter](https://github.com/mediacloud/sentence-splitter)\n",
    "        2. [NLTK](https://github.com/nltk/nltk)\n",
    "        3. write your own sentence splitter, a home-made example\n",
    "    - deduplicate documents based on similarity score\n",
    "    - (additional advice) discuss filtering on number of sentences per document and number of tokens per sentence \n",
    "        - example for English GPT training, it is recommand to check on the stats of your raw data and come-up with a good rule-of-thumb to proceed filtering, it is,however,recommanded to look into language-specific cleaning and follow up robust clearning procedure to obtain quality corpus.\n",
    "\n",
    "in this notebook, we will embrace the method provided by the [Megatron-LM repo](https://github.com/NVIDIA/Megatron-LM/tree/main/tools/openwebtext) as well as introduce other complimenting methods that might be of interest for data cleaning.\n",
    "\n",
    "---------------\n",
    "### At the end, there's a **mini challenge** for hands-on practice identifying number of duplicates approach groudtruth number!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-appraisal",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------\n",
    "#### start by install necessary libraries -\n",
    "\n",
    "    install LSH - \n",
    "\n",
    "    follow instruction from [Megatron-LM/tools/openwebtext/README](https://github.com/NVIDIA/Megatron-LM/tree/main/tools/openwebtext) in openwebtext clearning folder \n",
    "\n",
    "    note : in a restricted environment where sudo is not allowed, please follow the below instruction to modify installation ---\n",
    "            \n",
    "            call out a terminal             \n",
    "   ![call out a terminal ](../../pics/Alt_callout2terminals.JPG)\n",
    "   \n",
    "            cd gpubootcamp/ai/Megatron/English/Python/jupyter_notebook/Megatron-LM/tools/openwebtext/\n",
    "        \n",
    "            git clone https://github.com/mattilyra/LSH.git\n",
    "            cd LSH\n",
    "            pip install -U --user cython>=0.24.1\n",
    "            open setup.py in an editor and modify as below\n",
    "   ![modify setup.py line 6](../../pics/modifyLSH_setuppy.JPG)\n",
    "\n",
    "            python setup.py install --user "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "elect-chair",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting ftfy\n",
      "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
      "\u001b[K     |████████████████████████████████| 64 kB 3.1 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 30.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (1.19.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.9.0a0+df837d0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (1.1.4)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.8/site-packages (0.1.95)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.8/site-packages (1.17.32)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (4.53.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.8/site-packages (2021.3.17)\n",
      "Requirement already satisfied: bs4 in /home/x_zench/.local/lib/python3.8/site-packages (0.0.1)\n",
      "Collecting htmlmin\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "Collecting tldextract\n",
      "  Downloading tldextract-3.1.2-py2.py3-none-any.whl (87 kB)\n",
      "\u001b[K     |████████████████████████████████| 87 kB 10.3 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting sentence-splitter\n",
      "  Downloading sentence_splitter-1.4-py2.py3-none-any.whl (44 kB)\n",
      "\u001b[K     |████████████████████████████████| 44 kB 3.2 MB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from ftfy) (0.2.5)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from langdetect) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch) (3.7.4.3)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/lib/python3.8/site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.8/site-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.32 in /opt/conda/lib/python3.8/site-packages (from boto3) (1.20.32)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.3.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.8/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.8/site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: filelock>=3.0.8 in /opt/conda/lib/python3.8/site-packages (from tldextract) (3.0.12)\n",
      "Requirement already satisfied: requests>=2.1.0 in /opt/conda/lib/python3.8/site-packages (from tldextract) (2.24.0)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.8/site-packages (from tldextract) (2.10)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.32->boto3) (1.25.11)\n",
      "Requirement already satisfied: soupsieve>1.2; python_version >= \"3.0\" in /opt/conda/lib/python3.8/site-packages (from beautifulsoup4->bs4) (2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.1.0->tldextract) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.1.0->tldextract) (3.0.4)\n",
      "Building wheels for collected packages: ftfy, langdetect, htmlmin\n",
      "  Building wheel for ftfy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41914 sha256=c53e0371cfd741f088eee74f8f73b93014e7846ecdabc0b0f52157d3b014124b\n",
      "  Stored in directory: /home/x_zench/.cache/pip/wheels/7f/40/63/4bf603cec3ecc4a26985405834cb47eb8368bfa59e15dde046\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=755dd5f12ab2219ddb785b5ff2215d15cb75e189b9ff00fa01506c4caab14d18\n",
      "  Stored in directory: /home/x_zench/.cache/pip/wheels/13/c7/b0/79f66658626032e78fc1a83103690ef6797d551cb22e56e734\n",
      "  Building wheel for htmlmin (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27084 sha256=bf688cdafbb2a552e92b829fa0fc877d8739d7b32740491ea9ea0c04afdc6f61\n",
      "  Stored in directory: /home/x_zench/.cache/pip/wheels/23/14/6e/4be5bfeeb027f4939a01764b48edd5996acf574b0913fe5243\n",
      "Successfully built ftfy langdetect htmlmin\n",
      "Installing collected packages: ftfy, langdetect, htmlmin, requests-file, tldextract, sentence-splitter\n",
      "\u001b[33m  WARNING: The script ftfy is installed in '/home/x_zench/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script htmlmin is installed in '/home/x_zench/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The script tldextract is installed in '/home/x_zench/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed ftfy-6.0.3 htmlmin-0.1.12 langdetect-1.0.9 requests-file-1.5.1 sentence-splitter-1.4 tldextract-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy langdetect numpy torch pandas nltk sentencepiece boto3 tqdm regex bs4 htmlmin tldextract sentence-splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-madison",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------------------------\n",
    "## detect and filter undesired langauge in the raw text corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "choice-nicholas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "swe_raw_text='Under fredagsförmiddagen höll polis och räddningstjänst presskonferens tillsammans med en representanter från flygplatsens egna räddningsenhet och Örebro kommun.'\n",
    "detect(swe_raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "nonprofit-statistics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'da'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "danish_text='1. januar 2021 var folketallet 5.840.045. Ved den første folketælling i 1735 var der 718.000 danskere.'\n",
    "detect(danish_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adverse-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fi'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finnish_text='Jokaisella on oikeus vapaasti osallistua yhteiskunnan sivistyselämään, nauttia taiteista sekä päästä osalliseksi tieteen edistyksen mukanaan tuomista eduista.'\n",
    "detect(finnish_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interpreted-links",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "## finding sentence boundary - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "typical-accused",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/x_zench/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ranking-semester",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original doc is :\n",
      "  På sommarhalvåret längst vattnet och i skogarna på Lidingö eller på Djurgården – på vintern blir det löpbandet på gymmet .Händelsen skapade mycket oro inom klubben , eftersom skridskoåkning äger rum på sjöar och vattendrag där det givetvis inte finns någon gatuadress att uppge vid olycka .\n",
      "------- sentence 0 -------\n",
      "På sommarhalvåret längst vattnet och i skogarna på Lidingö eller på Djurgården – på vintern blir det löpbandet på gymmet .Händelsen skapade mycket oro inom klubben , eftersom skridskoåkning äger rum på sjöar och vattendrag där det givetvis inte finns någon gatuadress att uppge vid olycka .\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "text='På sommarhalvåret längst vattnet och i skogarna på Lidingö eller på Djurgården – på vintern blir det löpbandet på gymmet .Händelsen skapade mycket oro inom klubben , eftersom skridskoåkning äger rum på sjöar och vattendrag där det givetvis inte finns någon gatuadress att uppge vid olycka .'\n",
    "print(\"original doc is :\\n \", text)\n",
    "sents=sent_tokenize(text)\n",
    "i=0\n",
    "for sent in sents:\n",
    "    print(\"------- sentence {} -------\".format(str(i)))    \n",
    "    print(sent)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portable-bumper",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "## finding sentence boundary - Sentence-Splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "environmental-rating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-09-15 11:26:03--  https://github.com/mediacloud/sentence-splitter/blob/develop/sentence_splitter/non_breaking_prefixes/sv.txt\n",
      "Resolving github.com (github.com)... 140.82.121.4\n",
      "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/html]\n",
      "Saving to: ‘sv.txt’\n",
      "\n",
      "sv.txt                  [ <=>                ] 191.69K  --.-KB/s    in 0.08s   \n",
      "\n",
      "2021-09-15 11:26:04 (2.23 MB/s) - ‘sv.txt’ saved [196294]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://github.com/mediacloud/sentence-splitter/blob/develop/sentence_splitter/non_breaking_prefixes/sv.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "collective-medication",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv sv.txt custom_english_non_breaking_prefixes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "secure-encounter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- sentence 0 -------\n",
      "På sommarhalvåret längst vattnet och i skogarna på Lidingö eller på Djurgården – på vintern blir det löpbandet på gymmet .Händelsen skapade mycket oro inom klubben , eftersom skridskoåkning äger rum på sjöar och vattendrag där det givetvis inte finns någon gatuadress att uppge vid olycka .\n"
     ]
    }
   ],
   "source": [
    "from sentence_splitter import SentenceSplitter, split_text_into_sentences\n",
    "splitter = SentenceSplitter(language='sv', non_breaking_prefix_file='custom_english_non_breaking_prefixes.txt')\n",
    "sents=splitter.split(text=text)\n",
    "i=0\n",
    "for sent in sents:\n",
    "    print(\"------- sentence {} -------\".format(str(i)))  \n",
    "    print(sent)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-province",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "## finding sentence boundary - create your own sentence splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "voluntary-madness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "def normal_cut_sentence(temp):\n",
    "    return sent_tokenize(temp)\n",
    "\n",
    "def cut_sentence_with_quotation_marks(text):\n",
    "    p = re.compile(\"“.*?”\")\n",
    "    list = []\n",
    "    index = 0\n",
    "    length = len(text)\n",
    "    for i in p.finditer(text):\n",
    "        temp = ''\n",
    "        start = i.start()\n",
    "        end = i.end()\n",
    "        for j in range(index, start):\n",
    "            temp += text[j]\n",
    "        if temp != '':\n",
    "            temp_list = normal_cut_sentence(temp)\n",
    "            list += temp_list\n",
    "        temp = ''\n",
    "        for k in range(start, end):\n",
    "            temp += text[k]\n",
    "        if temp != ' ':\n",
    "            list.append(temp)\n",
    "        index = end\n",
    "    return list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "raising-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- sentence 1 -------\n",
      "Andersson pekas ut som nästa partiledare:\n",
      "------- sentence 2 -------\n",
      "“Medlemmarna ska säga sitt”\n"
     ]
    }
   ],
   "source": [
    "sample_doc='Andersson pekas ut som nästa partiledare: “Medlemmarna ska säga sitt”'\n",
    "sents=cut_sentence_with_quotation_marks(sample_doc)\n",
    "for sent in sents:\n",
    "    print(\"------- sentence {} -------\".format(str(i)))  \n",
    "    print(sent)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-trading",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------\n",
    "## deduplicate text based on similarity score  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agricultural-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from lsh import cache, minhash # https://github.com/mattilyra/lsh\n",
    "\n",
    "# a pure python shingling function that will be used in comparing\n",
    "# LSH to true Jaccard similarities\n",
    "def shingles(text, char_ngram=5):\n",
    "    return set(text[head:head + char_ngram] for head in range(0, len(text) - char_ngram))\n",
    "\n",
    "\n",
    "def jaccard(set_a, set_b):\n",
    "    intersection = set_a & set_b\n",
    "    union = set_a | set_b\n",
    "    return len(intersection) / len(union)\n",
    "\n",
    "\n",
    "def candidate_duplicates(document_feed, char_ngram=5, seeds=100, bands=5, hashbytes=4):\n",
    "    char_ngram = char_ngram\n",
    "    sims = []\n",
    "    hasher = minhash.MinHasher(seeds=seeds, char_ngram=char_ngram, hashbytes=hashbytes)\n",
    "    if seeds % bands != 0:\n",
    "        raise ValueError('Seeds has to be a multiple of bands. {} % {} != 0'.format(seeds, bands))\n",
    "    \n",
    "    lshcache = cache.Cache(num_bands=bands, hasher=hasher)\n",
    "    for i_line, line in enumerate(document_feed):\n",
    "        line = line.decode('utf8')\n",
    "        docid, headline_text = line.split('\\t', 1)\n",
    "        fingerprint = hasher.fingerprint(headline_text.encode('utf8'))\n",
    "        \n",
    "        # in addition to storing the fingerpring store the line\n",
    "        # number and document ID to help analysis later on\n",
    "        lshcache.add_fingerprint(fingerprint, doc_id=(i_line, docid))\n",
    "\n",
    "    candidate_pairs = set()\n",
    "    for b in lshcache.bins:\n",
    "        for bucket_id in b:\n",
    "            if len(b[bucket_id]) > 1:\n",
    "                pairs_ = set(itertools.combinations(b[bucket_id], r=2))\n",
    "                candidate_pairs.update(pairs_)\n",
    "    \n",
    "    return candidate_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "nonprofit-panama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given two documents \n",
    "doc1='I det här fallet fungerar kursen som en hjälp till elever.'\n",
    "shingles_1 = [doc1[i:i+5] for i in range(len(doc1))][:-5]\n",
    "doc2='På det sättet fungerar kursen som en hjälp till elever.'\n",
    "shingles_2 = [doc2[i:i+5] for i in range(len(doc2))][:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "empty-while",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61\n",
      "0.72\n",
      "0.6\n",
      "0.6\n",
      "0.66\n"
     ]
    }
   ],
   "source": [
    "from lsh import minhash\n",
    "for _ in range(5):\n",
    "    hasher = minhash.MinHasher(seeds=100, char_ngram=5)\n",
    "    fingerprint0 = hasher.fingerprint(doc1.encode('utf8'))\n",
    "    fingerprint1 = hasher.fingerprint(doc2.encode('utf8'))\n",
    "    print(sum(fingerprint0[i] in fingerprint1 for i in range(hasher.num_seeds)) / hasher.num_seeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-union",
   "metadata": {},
   "source": [
    "## dataset extracted from NVIDIA blog urls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "instant-grade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep learning models have been successfully us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Breast cancer is the most frequently diagnosed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The NVIDIA Deep Learning Institute (DLI) exten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Engineers, product developers and designers ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Despite substantial progress in natural langua...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                doc1\n",
       "0  Deep learning models have been successfully us...\n",
       "1  Breast cancer is the most frequently diagnosed...\n",
       "2  The NVIDIA Deep Learning Institute (DLI) exten...\n",
       "3  Engineers, product developers and designers ar...\n",
       "4  Despite substantial progress in natural langua..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cols=['doc1']\n",
    "df=pd.read_csv('../../../../dataset/EN/extractedNVblogs.txt',sep='\\n', names=cols ,skiprows=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-candle",
   "metadata": {},
   "source": [
    "## create our own groudtruth dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "constant-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_duplicates(df):\n",
    "    doc2=[]\n",
    "    duplicate=[]\n",
    "    n=len(df)\n",
    "    for i in range(n):\n",
    "        other_population=[k for k in range(n) if k!=i]\n",
    "        \n",
    "        other_idx=np.random.choice(other_population)\n",
    "        current_idx=np.random.choice([i,other_idx], p=[0.3,0.7])\n",
    "        if current_idx==i:            \n",
    "            duplicate.append(True)\n",
    "        else:\n",
    "            duplicate.append(False)\n",
    "        doc2.append(df.iloc[current_idx,0])\n",
    "    df['index']=df.index\n",
    "    df['doc2']=doc2\n",
    "    df['duplicate']=duplicate\n",
    "    cols=['index','doc1','doc2','duplicate']\n",
    "    df=df[cols]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accepting-truck",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>65</td>\n",
       "      <td>This post was updated July 20, 2021 to reflect...</td>\n",
       "      <td>This post was updated July 20, 2021 to reflect...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>66</td>\n",
       "      <td>Researchers, developers, and engineers worldwi...</td>\n",
       "      <td>This post was originally published in August 2...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>67</td>\n",
       "      <td>Looking to reveal secrets of days past, histor...</td>\n",
       "      <td>The NVIDIA Deep Learning Institute (DLI) exten...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>68</td>\n",
       "      <td>Scientists searching the universe for gravitat...</td>\n",
       "      <td>Robotics researchers from NVIDIA and Universit...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>69</td>\n",
       "      <td>At GTC ’21, experts presented a variety of tec...</td>\n",
       "      <td>The NVIDIA Hardware Grant Program helps advanc...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                               doc1  \\\n",
       "65     65  This post was updated July 20, 2021 to reflect...   \n",
       "66     66  Researchers, developers, and engineers worldwi...   \n",
       "67     67  Looking to reveal secrets of days past, histor...   \n",
       "68     68  Scientists searching the universe for gravitat...   \n",
       "69     69  At GTC ’21, experts presented a variety of tec...   \n",
       "\n",
       "                                                 doc2  duplicate  \n",
       "65  This post was updated July 20, 2021 to reflect...       True  \n",
       "66  This post was originally published in August 2...      False  \n",
       "67  The NVIDIA Deep Learning Institute (DLI) exten...      False  \n",
       "68  Robotics researchers from NVIDIA and Universit...      False  \n",
       "69  The NVIDIA Hardware Grant Program helps advanc...      False  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2=create_duplicates(df)\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acting-tiffany",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    45\n",
       "True     25\n",
       "Name: duplicate, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is our groundtruth, count duplicate == True is 31 \n",
    "df2.duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wicked-youth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'doc1', 'doc2', 'duplicate'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "rural-lotus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Deep learning models have been successfully us...</td>\n",
       "      <td>Deep learning models have been successfully us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Breast cancer is the most frequently diagnosed...</td>\n",
       "      <td>In NVIDIA Clara Train 4.0, we added homomorphi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The NVIDIA Deep Learning Institute (DLI) exten...</td>\n",
       "      <td>The NVIDIA Deep Learning Institute (DLI) exten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Engineers, product developers and designers ar...</td>\n",
       "      <td>Deep learning research requires working at sca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Despite substantial progress in natural langua...</td>\n",
       "      <td>NVIDIA announces our newest release of the CUD...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               doc1  \\\n",
       "0      0  Deep learning models have been successfully us...   \n",
       "1      1  Breast cancer is the most frequently diagnosed...   \n",
       "2      2  The NVIDIA Deep Learning Institute (DLI) exten...   \n",
       "3      3  Engineers, product developers and designers ar...   \n",
       "4      4  Despite substantial progress in natural langua...   \n",
       "\n",
       "                                                doc2  \n",
       "0  Deep learning models have been successfully us...  \n",
       "1  In NVIDIA Clara Train 4.0, we added homomorphi...  \n",
       "2  The NVIDIA Deep Learning Institute (DLI) exten...  \n",
       "3  Deep learning research requires working at sca...  \n",
       "4  NVIDIA announces our newest release of the CUD...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "keep_cols_to_write=['index','doc1','doc2']\n",
    "df3=df2[keep_cols_to_write]\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominican-trick",
   "metadata": {},
   "source": [
    "---\n",
    "To do this deterministically, let's simply read-in the previously saved df2.csv file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "married-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>doc1</th>\n",
       "      <th>doc2</th>\n",
       "      <th>duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Today, NVIDIA announced new pretrained models ...</td>\n",
       "      <td>Astrophysics researchers have long faced a tra...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>This post was updated July 20, 2021 to reflect...</td>\n",
       "      <td>This post was updated July 20, 2021 to reflect...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>In part 1 of this series, we introduced new AP...</td>\n",
       "      <td>Edge computing has been around for a long time...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The NVIDIA NGC team is hosting a webinar with ...</td>\n",
       "      <td>The NVIDIA NGC team is hosting a webinar with ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NVIDIA announces our newest release of the CUD...</td>\n",
       "      <td>As an undergraduate student excited about AI f...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                               doc1  \\\n",
       "0      0  Today, NVIDIA announced new pretrained models ...   \n",
       "1      1  This post was updated July 20, 2021 to reflect...   \n",
       "2      2  In part 1 of this series, we introduced new AP...   \n",
       "3      3  The NVIDIA NGC team is hosting a webinar with ...   \n",
       "4      4  NVIDIA announces our newest release of the CUD...   \n",
       "\n",
       "                                                doc2  duplicate  \n",
       "0  Astrophysics researchers have long faced a tra...      False  \n",
       "1  This post was updated July 20, 2021 to reflect...       True  \n",
       "2  Edge computing has been around for a long time...      False  \n",
       "3  The NVIDIA NGC team is hosting a webinar with ...       True  \n",
       "4  As an undergraduate student excited about AI f...      False  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to do this deterministically , let's read in the saved df2.csv file\n",
    "df2=pd.read_csv('df2.csv', names=['index', 'doc1', 'doc2', 'duplicate'], skiprows=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rocky-courage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    42\n",
       "True     31\n",
       "Name: duplicate, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is our groundtruth, count duplicate == Truth is 31 \n",
    "df2.duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "boring-piece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 groundtruth.txt\n"
     ]
    }
   ],
   "source": [
    "!wc -l groundtruth.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-norfolk",
   "metadata": {},
   "source": [
    "---\n",
    "## Re-run the below cell for experiments\n",
    "<a id=\"Rerun_Cell\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "starting-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pair of similar sentences with jaccard_sim score:0.8197797952482132 and minhash_sim score:0.639344262295082 --- \n",
      "\n",
      "text_a: ['The', 'NVIDIA,', 'Facebook,', 'and', 'TensorFlow']\n",
      "text_b: ['Deep', 'learning', '(DL)', 'is', 'the']\n",
      "--------------------------------------------------\n",
      "pair of similar sentences with jaccard_sim score:0.9133693568066934 and minhash_sim score:0.8867924528301887 --- \n",
      "\n",
      "100% duplicates \n",
      "\n",
      "text_a: ['The', 'first', 'post', 'in', 'this']\n",
      "text_b: ['The', 'first', 'post', 'in', 'this']\n",
      "--------------------------------------------------\n",
      "\n",
      "There are **3** candidate duplicates in total\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('25', '51', 0.9685534591194969, 0.9607843137254902)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is the Re Run Cell \n",
    "import itertools\n",
    "import random\n",
    "lines = []\n",
    "with open('groundtruth.txt', 'rb') as fh:\n",
    "    # read the first 1000 lines into memory so we can compare them\n",
    "    for line in itertools.islice(fh, 1000):\n",
    "        lines.append(line.decode('utf8'))\n",
    "    \n",
    "    # reset file pointer and do LSH\n",
    "    fh.seek(0)\n",
    "    feed = itertools.islice(fh, 1000)\n",
    "    \"\"\"\n",
    "    ## modify the below numbers as input to function candidate_duplicates()\n",
    "    char_ngram= < input_value >\n",
    "    seeds=< input_value >\n",
    "    bands=< input_value >\n",
    "    hashbytes=< input_value >\n",
    "    \"\"\"\n",
    "    # initial value given below\n",
    "    char_ngram=13\n",
    "    seeds=100\n",
    "    bands=5\n",
    "    hashbytes=8\n",
    "    \n",
    "    candidates = candidate_duplicates(feed, char_ngram=char_ngram, seeds=seeds, bands=bands, hashbytes=hashbytes)\n",
    "\n",
    "# go over all the generated candidates comparing their similarities\n",
    "similarities = []\n",
    "for ((line_a, docid_a), (line_b, docid_b)) in candidates:\n",
    "    doc_a, doc_b = lines[line_a], lines[line_b]\n",
    "    shingles_a = shingles(lines[line_a])\n",
    "    shingles_b = shingles(lines[line_b])\n",
    "    \n",
    "    jaccard_sim = jaccard(shingles_a, shingles_b)\n",
    "    fingerprint_a = set(hasher.fingerprint(doc_a.encode('utf8')))\n",
    "    fingerprint_b = set(hasher.fingerprint(doc_b.encode('utf8')))\n",
    "    minhash_sim = len(fingerprint_a & fingerprint_b) / len(fingerprint_a | fingerprint_b)\n",
    "    similarities.append((docid_a, docid_b, jaccard_sim, minhash_sim))\n",
    "\n",
    "for a,b,jsim, msim in random.sample(similarities, k=2 ):\n",
    "    print(\"pair of similar sentences with jaccard_sim score:{} and minhash_sim score:{} --- \\n\".format(str(jsim),str(msim)))\n",
    "    a=int(a)\n",
    "    b=int(b)\n",
    "    text_a=df2.iloc[a,1]\n",
    "    text_b=df2.iloc[b,2]\n",
    "    if text_a==text_b:\n",
    "        print(\"100% duplicates \\n\")\n",
    "    print(\"text_a:\", text_a.split(' ')[:5])\n",
    "    print(\"text_b:\", text_b.split(' ')[:5])\n",
    "    print('-----'*10)\n",
    "    import random\n",
    "\n",
    "print('\\nThere are **{}** candidate duplicates in total\\n'.format(len(candidates)))\n",
    "random.sample(similarities, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-dispute",
   "metadata": {},
   "source": [
    "---\n",
    "## WOW that is way too LOW !!! Let's take a look at groundtruth, we should have 31 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "spread-entity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    42\n",
       "True     31\n",
       "Name: duplicate, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## this is our groundtruth, count duplicate == True is 31 \n",
    "df2.duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "exempt-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up \n",
    "!rm custom_english_non_breaking_prefixes.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-valuation",
   "metadata": {},
   "source": [
    "<a id=\"TheChallenge\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-external",
   "metadata": {},
   "source": [
    "---\n",
    "# Mini Challenge - approaching the groundtruth !\n",
    "\n",
    "Task : Aiming to approach the number 31 modifying the below parameters\n",
    "rerun cell <a href=\"./Day3-2_SentenceBoundary_and_Deduplicate.ipynb#Rerun_Cell\">Jump to ReRun Cell</a>\n",
    "\n",
    "Consider yourself pass this mini challenge when you approach the number **31 +/- 3** ! \n",
    "\n",
    "\n",
    "experiment on the below parameters and achieve as close as possilbe the deplicated documents in groundtruth ( which is 31 in our case ) \n",
    "\n",
    "            char_ngram= < input_value >\n",
    "            seeds=< input_value >\n",
    "            bands=< input_value >\n",
    "            hashbytes=< input_value >\n",
    "\n",
    "Solution will be delivered to you at the end of the bootcamp !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "sophisticated-boating",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 1 pairs with similarity >= 90% 0 were found, that's 0.0%\n"
     ]
    }
   ],
   "source": [
    "# turn the candidates into a dictionary so we have easy access to\n",
    "# candidates pairs that were found\n",
    "candidates_dict = {(line_a, line_b): (docid_a, docid_b) for ((line_a, docid_a), (line_b, docid_b)) in candidates}\n",
    "found = 0\n",
    "for i in range(len(lines)):\n",
    "    for j in range(i+1, len(lines)):\n",
    "        if sims_all[i, j] >= .9:\n",
    "            # documents i and j have an actual Jaccard similarity >= 90%\n",
    "            found += ((i, j) in candidates_dict or (j, i) in candidates_dict)\n",
    "\n",
    "print('Out of {} pairs with similarity >= 90% {} were found, that\\'s {:.1%}'.format((sims_all >= .9).sum(), found, found / (sims_all >= .9).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "meaningful-sample",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_candidates = []\n",
    "bands = [2, 5, 10, 20]\n",
    "for num_bands in bands:\n",
    "    with open('groundtruth.txt', 'rb') as fh:\n",
    "        feed = itertools.islice(fh, 1000)\n",
    "        candidates = candidate_duplicates(feed, char_ngram=5, seeds=100, bands=num_bands, hashbytes=4)\n",
    "        num_candidates.append(len(candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "operational-steps",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "plt.bar(bands, num_candidates, align='center');\n",
    "plt.title('Number of candidate duplicate pairs found by LSH using 100 minhash fingerprint.');\n",
    "plt.xlabel('Number of bands');\n",
    "plt.ylabel('Number of candidate duplicates');\n",
    "plt.xticks(bands, bands);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revolutionary-framing",
   "metadata": {},
   "source": [
    "---\n",
    "## Up Next : \n",
    "\n",
    "[Train your own GPTBPE Tokenizer on your own data ](../../../Day3-3_train_own_GPT2BPETokenizer.ipynb)\n",
    "\n",
    "## Back To Start Menu\n",
    "[start menu](../../../../Start_Here.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-greeting",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "\n",
    "## Licensing \n",
    "\n",
    "This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
