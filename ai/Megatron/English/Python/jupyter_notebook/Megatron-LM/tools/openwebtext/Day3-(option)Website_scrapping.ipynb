{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tough-nomination",
   "metadata": {},
   "source": [
    "# \n",
    "\n",
    "# (option) : get your own data via scrap the website you have permisson to use\n",
    "\n",
    "note1 : strongly recommand to consult with your own legal department for compliance before proceeding this step on websites/webpages you have permission to\n",
    "\n",
    "note2 : modification needed when applying to different website/webpages\n",
    "\n",
    "note3 : use at your own risk !\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "- **The goal of this lab is to demonstrate that there are ways to obtain your own data via webscrapping sites which you have permission to**\n",
    "    - Provide a list of urls in a text file via collecting webpages links\n",
    "    \n",
    "    the base url used to crawl links from is  https://developer.nvidia.com/blog/\n",
    "    \n",
    "    - scrap the webpage ( in html format ) using [scrapy](https://docs.scrapy.org/en/latest/index.html) and obtain desired text, concatenate text per webpage into one raw text file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considered-edmonton",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4\n",
    "!pip install html5lib\n",
    "!pip install PyPDF2\n",
    "!pip install selenium\n",
    "!pip install Scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-payday",
   "metadata": {},
   "source": [
    "## crawl NVblog landing page and obtain links to the individual blogs\n",
    "source github repo : https://github.com/x4nth055/pythoncode-tutorials/tree/master/web-scraping/link-extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focal-ethiopia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-27 04:15:35--  https://raw.githubusercontent.com/x4nth055/pythoncode-tutorials/master/web-scraping/link-extractor/link_extractor.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3485 (3.4K) [text/plain]\n",
      "Saving to: ‘link_extractor.py’\n",
      "\n",
      "link_extractor.py   100%[===================>]   3.40K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-08-27 04:15:35 (34.9 MB/s) - ‘link_extractor.py’ saved [3485/3485]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/x4nth055/pythoncode-tutorials/master/web-scraping/link-extractor/link_extractor.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premium-trust",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/x4nth055/pythoncode-tutorials/master/web-scraping/link-extractor/link_extractor_js.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests bs4 colorama requests-html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alone-advocacy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[*] Crawling: https://blogs.nvidia.com/blog/category/deep-learning/\u001b[39m\n",
      "[W:pyppeteer.chromium_downloader] Starting Chromium download. Download may take a few minutes.\n",
      "100%|████████████████████████████████████████| 109M/109M [00:01<00:00, 55.0Mb/s]\n",
      "[W:pyppeteer.chromium_downloader] Chromium download done.\n",
      "[W:pyppeteer.chromium_downloader] chromium extracted to: /root/.local/share/pyppeteer/local-chromium/588429\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/deep-learning/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com\u001b[39m\n",
      "\u001b[90m[!] External link: https://twitter.com/nvidia\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.facebook.com/NVIDIA\u001b[39m\n",
      "\u001b[90m[!] External link: https://news.ycombinator.com/submit\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.instagram.com/nvidia/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.linkedin.com/company/nvidia/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.reddit.com/r/nvidia/\u001b[39m\n",
      "\u001b[90m[!] External link: https://feeds.feedburner.com/nvidiablog\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.twitch.tv/nvidia\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.youtube.com/nvidia\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/privacy-commenting-policy/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/legal-info/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/contact/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/enterprise/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/auto/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/gaming/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/pro-graphics/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/autonomous-machines/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/medical-research-and-healthcare/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/inception/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/ai-podcast/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/16/what-is-a-machine-learning-model/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/13/nvidia-brings-metaverse-momentum-research-breakthroughs-and-new-pro-gpu-to-siggraph/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/11/omniverse-making-of-gtc/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/11/lending-a-helping-hand-jules-anh-tuan-nguyen-on-building-a-neuroprosthetic/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/12/geforce-now-thursday-august-12/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/11/cloudxr-google-cloud-demo/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/10/omniverse-connector-extension-plugin-siggraph/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/ai-computing/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/technologies/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/research/\u001b[39m\n",
      "\u001b[90m[!] External link: https://investor.nvidia.com/home/default.aspx\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/csr/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/foundation/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/forums/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/careers/\u001b[39m\n",
      "\u001b[90m[!] External link: https://developer.nvidia.com/\u001b[39m\n",
      "\u001b[90m[!] External link: https://developer.nvidia.com/developer-program\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/partners/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/deep-learning-ai/startups/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/deep-learning-ai/startups/venture-capital/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/gpu-ventures/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/training/\u001b[39m\n",
      "\u001b[90m[!] External link: https://academy.mellanox.com/en/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/ai-data-science/professional-services/\u001b[39m\n",
      "\u001b[90m[!] External link: https://nvidianews.nvidia.com/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/about-nvidia/webinar-portal/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/preferences/email-signup/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/events/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/gtc/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/on-demand/\u001b[39m\n",
      "\u001b[90m[!] External link: mailto://blogideas@nvidia.com\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/contact/social/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/location-selector/\u001b[39m\n",
      "\u001b[90m[!] External link: https://twitter.com/intent/tweet\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.facebook.com/dialog/share\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/wp-admin/admin-ajax.php\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.linkedin.com/shareArticle\u001b[39m\n",
      "\u001b[33m[*] Crawling: https://blogs.nvidia.com/blog/category/pro-graphics/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/11/applications-open-graduate-fellowship-awards/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/08/10/siggraph-real-time-live-demo/\u001b[39m\n",
      "\u001b[33m[*] Crawling: https://blogs.nvidia.com/blog/2021/08/10/siggraph-real-time-live-demo/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/author/ishasalian/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.facebook.com/sharer/sharer.php\u001b[39m\n",
      "\u001b[90m[!] External link: http://news.ycombinator.com/submitlink\u001b[39m\n",
      "\u001b[90m[!] External link: https://s2021.siggraph.org/program/real-time-live/\u001b[39m\n",
      "\u001b[90m[!] External link: https://s2021.siggraph.org/presentation/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/design-visualization/rtx-professional-laptops/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/design-visualization/rtx-a6000/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/2021/06/24/vid2vid-cameo-ai-research-video-conferencing/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/omniverse/apps/audio2face/\u001b[39m\n",
      "\u001b[90m[!] External link: https://github.com/NVlabs/stylegan\u001b[39m\n",
      "\u001b[90m[!] External link: https://openreview.net/pdf\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.nvidia.com/en-us/events/siggraph/\u001b[39m\n",
      "\u001b[90m[!] External link: https://www.youtube.com/watch\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/category/nvidia-research/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/artificial-intelligence/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/events/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/nvidia-research/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/nvidia-rtx/\u001b[39m\n",
      "\u001b[32m[*] Internal link: https://blogs.nvidia.com/blog/tag/siggraph/\u001b[39m\n",
      "[+] Total Internal links: 30\n",
      "[+] Total External links: 53\n",
      "[+] Total URLs: 83\n",
      "[+] Total crawled URLs: 2\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python link_extractor_js.py https://blogs.nvidia.com/blog/category/deep-learning/ -m 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "conceptual-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as request\n",
    "import re\n",
    "import scrapy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-surgeon",
   "metadata": {},
   "source": [
    "## fetch the urls of interest and convert to html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "discrete-coupon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('training_optimizing_2d_pose_estimation_model_with_tlt_part_2.html',\n",
       " 'https://developer.nvidia.com/blog/training-optimizing-2d-pose-estimation-model-with-tlt-part-2/')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "import os, sys\n",
    "f=open('NVdevblog_urls.txt','r')\n",
    "lines=f.readlines()\n",
    "rn=random.randint(0,len(lines)-1)\n",
    "url=str(lines[rn]).strip()\n",
    "name=url.split(':')[1][2:].split('/')[-2].replace('-','_')+'.html'\n",
    "name=str(name)\n",
    "name, url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "based-dancing",
   "metadata": {},
   "source": [
    "## fetch given url and save as .html file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mounted-breeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: scrapy: command not found\n"
     ]
    }
   ],
   "source": [
    "!scrapy fetch --nolog $url > ./htmls/$name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "continent-therapy",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import scrapy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "persistent-advisory",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./htmls/response_0.html\n",
      "./htmls/response_1.html\n",
      "./htmls/response_2.html\n",
      "./htmls/response_3.html\n",
      "./htmls/response_4.html\n",
      "./htmls/response_5.html\n",
      "./htmls/response_6.html\n",
      "./htmls/response_7.html\n",
      "./htmls/response_8.html\n",
      "./htmls/response_9.html\n",
      "./htmls/response_10.html\n",
      "./htmls/response_11.html\n",
      "./htmls/response_12.html\n",
      "./htmls/response_13.html\n",
      "./htmls/response_14.html\n",
      "./htmls/response_15.html\n",
      "./htmls/response_16.html\n",
      "./htmls/response_17.html\n",
      "./htmls/response_18.html\n",
      "./htmls/response_19.html\n",
      "./htmls/response_20.html\n",
      "./htmls/response_21.html\n",
      "./htmls/response_22.html\n",
      "./htmls/response_23.html\n",
      "./htmls/response_24.html\n",
      "./htmls/response_25.html\n",
      "./htmls/response_26.html\n",
      "./htmls/response_27.html\n",
      "./htmls/response_28.html\n",
      "./htmls/response_29.html\n",
      "./htmls/response_30.html\n",
      "./htmls/response_31.html\n",
      "./htmls/response_32.html\n",
      "./htmls/response_33.html\n",
      "./htmls/response_34.html\n",
      "./htmls/response_35.html\n",
      "./htmls/response_36.html\n",
      "./htmls/response_37.html\n",
      "./htmls/response_38.html\n",
      "./htmls/response_39.html\n",
      "./htmls/response_40.html\n",
      "./htmls/response_41.html\n",
      "./htmls/response_42.html\n",
      "./htmls/response_43.html\n",
      "./htmls/response_44.html\n",
      "./htmls/response_45.html\n",
      "./htmls/response_46.html\n",
      "./htmls/response_47.html\n",
      "./htmls/response_48.html\n",
      "./htmls/response_49.html\n",
      "./htmls/response_50.html\n",
      "./htmls/response_51.html\n",
      "./htmls/response_52.html\n",
      "./htmls/response_53.html\n",
      "./htmls/response_54.html\n",
      "./htmls/response_55.html\n",
      "./htmls/response_56.html\n",
      "./htmls/response_57.html\n",
      "./htmls/response_58.html\n",
      "./htmls/response_59.html\n",
      "./htmls/response_60.html\n",
      "./htmls/response_61.html\n",
      "./htmls/response_62.html\n",
      "./htmls/response_63.html\n",
      "./htmls/response_64.html\n",
      "./htmls/response_65.html\n",
      "./htmls/response_66.html\n",
      "./htmls/response_67.html\n",
      "./htmls/response_68.html\n",
      "./htmls/response_69.html\n",
      "./htmls/response_70.html\n"
     ]
    }
   ],
   "source": [
    "!bash fetchURLs_and_write2html.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "collect-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import csv\n",
    "import html5lib\n",
    "import codecs\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "backed-radio",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish processing htmls files and convert them to \n"
     ]
    }
   ],
   "source": [
    "# read the html into python\n",
    "\n",
    "def covert2txt(html_f ,f_out):\n",
    "    file = codecs.open(html_f, \"r\", \"utf-8\")\n",
    "    html_doc=file.read()\n",
    "    soup = BeautifulSoup(html_doc)\n",
    "    sent_cnt=0\n",
    "    for node in soup.findAll('p'):\n",
    "        #print(type(node.text), node.text)\n",
    "        if node.text not in ['/n','','\\t',' ','\\n\\r'] : \n",
    "            sent_cnt+=1\n",
    "            f_out.write(node.text)            \n",
    "    f_out.write('\\n')      \n",
    "html_dir='./htmls/'\n",
    "htmls=os.listdir('./htmls')\n",
    "f_out=open('/home/zcharpy/bootcamp/jupyter_notebook/Megatron-LM/dataset/EN/extractedNVblogs.txt' , 'a')\n",
    "for html in htmls:\n",
    "    outtxt=html.split('.')[0]   \n",
    "    covert2txt(html_dir+html ,f_out)\n",
    "f_out.close()\n",
    "print(\"finish processing htmls files and convert them to \")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "#url='https://developer.nvidia.com/blog/accelerating-billion-vector-similarity-searches-with-gpus/'\n",
    "#headers = {'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:90.0) Gecko/20100101 Firefox/90.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "heard-translator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientists searching the universe for gravitational waves just got a boost thanks to a new study and AI. The research, recently published in Nature Astronomy, creates a deployable AI framework for detecting gravitational waves within massive amounts of data—at several magnitudes faster than real time. Created by a group of scientists from Argonne National Laboratory, the University of Chicago, the University of Illinois at Urbana-Champaign, NVIDIA, and IBM, the work highlights how AI and supercomputing can accelerate reproducible, data-driven discoveries.“As a computer scientist, what’s exciting to me about this project is that it shows how, with the right tools, AI methods can be integrated naturally into the workflows of scientists. Allowing them to do their work faster and better. Augmenting, not replacing, human intelligence,” study senior author Ian Foster, director of Argonne’s Data Science and Learning division said in a press release.In 2015, the advanced Laser Interferometer Gravitational-Wave Observatory (LIGO) first detected gravitational waves when two black holes, 1.3 billion light-years away, collided and merged. These waves occur when massive objects quickly accelerate (such as a star exploding or massive objects colliding) creating a ripple through space time.The notable discovery confirmed part of Einstein’s theory of relativity, hypothesizing that space and time are linked. It also marked the start of gravitational wave astronomy, which could result in a deeper understanding of the cosmos, including dark energy, gravity, and neutron stars. It also holds potential for scientists to step back through time to the moments around the Big Bang.Since 2015, many more gravitational wave sources have been detected from LIGO. As the observatory continues with sensor upgrades and refinements, the expanse of detectors within the universe will also grow, creating large amounts of data for processing. Quickly computing these data streams remains key to gravitational wave astronomy advancements and discoveries.In 2018 Eliu Huerta, lead for Translational AI at Argonne, demonstrated the capability of machine learning to detect gravitational waves from multiple LIGO detector data streams.In this study, the researchers further refined the model, which uses the cuDNN-accelerated deep learning framework distributed over 64 NVIDIA GPUs. They tested the model against LIGO data from 2017 and found it accurately identified four binary black hole mergers—without any misclassifications. It also processed a month’s worth of data in under 7 minutes. “In this study, we’ve used the combined power of AI and supercomputing to help solve timely and relevant big-data experiments. We are now making AI studies fully reproducible, not merely ascertaining whether AI may provide a novel solution to grand challenges,” Huerta said.The team’s models are open-source and readily available. Read the full article in Nature Astronomy >>Read more >>   Have a story to share? Submit an idea.Get the developer news feed straight to your inbox.\n"
     ]
    }
   ],
   "source": [
    "!head -1 /home/zcharpy/bootcamp/jupyter_notebook/Megatron-LM/dataset/EN/extractedNVblogs.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "velvet-calculation",
   "metadata": {},
   "source": [
    "## fetch text from the html document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-discharge",
   "metadata": {},
   "source": [
    "![scrapy workflow](../pics/scrapyworkflow.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "contrary-flooring",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.8'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Settings for notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "# Show Python version\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "introductory-milwaukee",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    !pip install scrapy\n",
    "    import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alone-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NVdevblogCrawler(scrapy.Spider):\n",
    "    name = \"NVdevblogCrawler\"\n",
    "    start_urls = ['https://developer.nvidia.com/blog/accelerating-billion-vector-similarity-searches-with-gpus/']\n",
    "    def parse(self, response):\n",
    "        SET_SELECTOR = '.post'\n",
    "        for tutorial in response.css(SET_SELECTOR):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "measured-bermuda",
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "manufactured-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class NVIDIABlogFetch(scrapy.Spider):\n",
    "    name = \"NVBlogFetch\"\n",
    "    start_urls = [\n",
    "        'https://developer.nvidia.com/blog/',\n",
    "    ]\n",
    "    \n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {'__main__.ExtractFirstLine': 1},\n",
    "    }\n",
    "        \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.mw-parser-output > p '):\n",
    "            yield {'quote': quote.extract()}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "reported-assessment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "class NVIDIABlogFetchcsv(scrapy.Spider):\n",
    "    name = \"NVIDIABlogFetchcsv\"\n",
    "    start_urls = [\n",
    "        'https://en.wikiquote.org/wiki/Marilyn_Manson',\n",
    "    ]\n",
    "    \n",
    "    custom_settings = {\n",
    "        'ITEM_PIPELINES': {'__main__.ExtractFirstLine': 1},\n",
    "        'FEED_FORMAT':'csv',\n",
    "        'FEED_URI': './outtxt/NVblog_parsed.csv'\n",
    "    }\n",
    "        \n",
    "    def parse(self, response):\n",
    "        for quote in response.css('div.mw-parser-output > p '):\n",
    "            yield {'quote': quote.extract()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "infectious-nursing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-12 13:15:31 [scrapy.utils.log] INFO: Scrapy 2.5.0 started (bot: scrapybot)\n",
      "2021-08-12 13:15:31 [scrapy.utils.log] INFO: Versions: lxml 4.6.3.0, libxml2 2.9.10, cssselect 1.1.0, parsel 1.6.0, w3lib 1.22.0, Twisted 21.7.0, Python 3.8.8 (default, Feb 24 2021, 21:46:12) - [GCC 7.3.0], pyOpenSSL 19.1.0 (OpenSSL 1.1.1j  16 Feb 2021), cryptography 3.2.1, Platform Linux-5.4.0-80-generic-x86_64-with-glibc2.10\n",
      "2021-08-12 13:15:31 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.epollreactor.EPollReactor\n",
      "2021-08-12 13:15:31 [scrapy.crawler] INFO: Overridden settings:\n",
      "{'LOG_LEVEL': 30,\n",
      " 'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:90.0) '\n",
      "               'Gecko/20100101 Firefox/90.0'}\n",
      "2021-08-12 13:15:31 [py.warnings] WARNING: /opt/conda/lib/python3.8/site-packages/scrapy/extensions/feedexport.py:247: ScrapyDeprecationWarning: The `FEED_URI` and `FEED_FORMAT` settings have been deprecated in favor of the `FEEDS` setting. Please see the `FEEDS` setting docs for more details\n",
      "  exporter = cls(crawler)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Deferred at 0x7fe897bbac40>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:90.0) Gecko/20100101 Firefox/90.0'\n",
    "})\n",
    "\n",
    "process.crawl(QuotesSpider)\n",
    "process.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
