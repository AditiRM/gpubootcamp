{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39ad569e",
   "metadata": {},
   "source": [
    "# The Application\n",
    "\n",
    "This section provides an overview of the scientific problem we focus on and the solver we employ. Then, we execute the single GPU version of the application program.\n",
    "\n",
    "### Laplace Equation\n",
    "\n",
    "Laplace Equation is a well-studied linear partial differential equation that governs steady state heat conduction, irrotational fluid flow, and many other phenomena. \n",
    "\n",
    "In this lab, we will consider the 2D Laplace Equation on a rectangle with Dirichlet boundary conditions on the left and right boundary and periodic boundary conditions on top and bottom boundary. We wish to solve the following equation:\n",
    "\n",
    "$\\Delta u(x,y) = 0\\;\\forall\\;(x,y)\\in\\Omega,\\delta\\Omega$\n",
    "\n",
    "### Jacobi Method\n",
    "\n",
    "The Jacobi method is an iterative algorithm to solve a linear system of strictly diagonally dominant equations. The governing Laplace equation is discretized and converted to a matrix amenable to Jacobi-method based solver.\n",
    "\n",
    "### The Code\n",
    "\n",
    "The GPU processing flow follows 3 key steps:\n",
    "\n",
    "1. Copy data from CPU to GPU\n",
    "2. Launch GPU Kernel\n",
    "3. Copy processed data back to CPU from GPU\n",
    "\n",
    "![gpu_programming_process](../../images/gpu_programming_process.png)\n",
    "\n",
    "Let's understand the single-GPU code first. The source code file is available here: [jacobi.cu](../../source_code/single_gpu/jacobi.cu).\n",
    "\n",
    "Alternatively, you can open the `File` menu and click on the `Open...` option which opens Jupyter's file explorer in a new tab. Then, navigate to `CFD/English/C/source_code/single_gpu/` directory in which you can view the `jacobi.cu` file. \n",
    "\n",
    "Similarly, have look at the [Makefile](../../source_code/single_gpu/Makefile). \n",
    "\n",
    "Refer to the `single_gpu(...)` function. The important steps at each iteration of the Jacobi Solver (that is, the `while` loop) are:\n",
    "1. The norm is set to 0 using `cudaMemset`.\n",
    "2. The device kernel `jacobi_kernel` is called to update the interier points.\n",
    "3. The norm is copied back to the host using `cudaMemcpy` (DtoH), and\n",
    "4. The periodic boundary conditions are re-applied for the next iteration using `cudaMemcpy` (DtoD).\n",
    "\n",
    "Note that we run the Jacobi solver for 1000 iterations over the grid.\n",
    "\n",
    "### Compilation and Execution\n",
    "\n",
    "Let's first get an overview of the CUDA driver version and the GPUs running on the server by executing the `nvidia-smi` command below. Highlight the cell below by clicking on it and then either hit `Ctrl+Enter` on the keyboard or click on the `Run` button on the toolbar above. The output will be visible below the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb46488",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97f825b",
   "metadata": {},
   "source": [
    "We will now compile the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2daf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../source_code/single_gpu && make clean && make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33345661",
   "metadata": {},
   "source": [
    "Now, let us execute the program: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234f430",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../source_code/single_gpu && ./jacobi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bb863e",
   "metadata": {},
   "source": [
    "The output reports the norm value every 100 iterations and the total execution time of the Jacobi Solver. The expected output is:\n",
    "\n",
    "```\n",
    "Single GPU jacobi relaxation: 1000 iterations on 16384 x 16384 mesh\n",
    "    0, 31.999022\n",
    "  100, 0.897983\n",
    "  200, 0.535684\n",
    "  300, 0.395651\n",
    "  400, 0.319039\n",
    "  500, 0.269961\n",
    "  600, 0.235509\n",
    "  700, 0.209829\n",
    "  800, 0.189854\n",
    "  900, 0.173818\n",
    "16384x16384: 1 GPU:   4.4512 s\n",
    "```\n",
    "\n",
    "The execution time may differ depending on the GPU, but the norm value after every 100 iterations should be the same. The program accepts `-nx` and `-ny` flags to change the grid size (preferably a power of 2) and `-niter` flag to change the number of iterations.\n",
    "\n",
    "\n",
    "# Profiling\n",
    "\n",
    "While the program in our labs gives the execution time in its output, it may not always be convinient to time the execution from within the program. Moreover, just timing the execution does not reveal the bottlenecks directly. For that purpose, we profile the program with NVIDIA's NSight Systems profiler's command-line interface (CLI), `nsys`. \n",
    "\n",
    "### NVIDIA Nsight Systems\n",
    "\n",
    "Nsight Systems profiler offers system-wide performance analysis in order to visualize applicationâ€™s execution timeline and help identify optimization opportunities on a system with multiple CPUs and GPUs.\n",
    "\n",
    "#### Timeline\n",
    "\n",
    "![Nsight Systems timeline](../../images/nsys_overview.png)\n",
    "\n",
    "The highlighted portions are identified as follows:\n",
    "* <span style=\"color:red\">Red</span>: The CPU tab provides thread-level core utilization data. \n",
    "* <span style=\"color:blue\">Blue</span>: The CUDA HW tab displays GPU kernel and memory transfer activities and API calls.\n",
    "* <span style=\"color:orange\">Orange</span>: The Threads tab gives a detailed view of each CPU thread's activity including from OS runtime libraries, MPI, NVTX, etc.\n",
    "\n",
    "#### `nsys` CLI\n",
    "\n",
    "We will profile the application using `nsys` CLI. Here's a typical `nsys` command to profile a program:\n",
    "\n",
    "`nsys profile --trace=cuda,nvtx --stats=true -o jacobi_report --force-overwrite true ./jacobi`\n",
    "\n",
    "The `--trace` flag specifies that we want to trace CUDA and NVTX APIs (in addition to baseline tracing), `--stats` specifies that we want to generate a statistics summary after profiling, and `-o` allows us to name the report file (which will include the `.qdrep` extension). The `--force-overwrite` flag allows us to overwrite an existing report (of the same name).\n",
    "\n",
    "Note that we can always use the `nsys --help` to know more about these and other available options.\n",
    "\n",
    "### Viewing the Report\n",
    "\n",
    "One can view the profiling report by using Nsight Systems GUI. Note that CUDA toolkit and the GUI application of the same version as CLI are required. Follow these steps:\n",
    "* Open Nsight Systems GUI application.\n",
    "* Click on _file $\\rightarrow$ open_.\n",
    "* Browse and select the `.qdrep` file.\n",
    "\n",
    "Alternatively, we can enable the `--stats` flag to display profiling data on the terminal (refer to the image below).\n",
    "\n",
    "![nsys cli sample output](../../images/nsys_cli_sample_output.png)\n",
    "\n",
    "### NVIDIA Tools Extension (NVTX)\n",
    "\n",
    "NVTX is C-based API for annotating events in applications. It is useful for profiling both specific events and large code blocks. We will routinely make use of NVTX APIs to instrument our application for `nsys` profiler. It helps `nsys` in collecting relevant information and improves the application timeline's readability. \n",
    "\n",
    "To use NVTX, follow these steps:\n",
    "* `#include <nvToolsExt.h>` in the code file\n",
    "* Insert `nvtxRangePush(\"myCodeBlock\");` just before the code block begins and `nvtxRangePop();` just after it ends.\n",
    "\n",
    "Now, go back to the [jacobi.cu](../../source_code/single_gpu/jacobi.cu) source code file and correlate the \"Jacobi solve\" annotated event visible on both the `nsys` CLI statistics and the GUI-based timeline to its use in the source code.\n",
    "\n",
    "### Improving performance\n",
    "\n",
    "Any code snippet can be taken up for optimizations. However, it is important to realize that our current code is limited to a single GPU. Usually a very powerful first optimization is to parallelize the code, which in our case means running it on multiple GPUs. Thus, we generally follow the cyclical process:\n",
    "\n",
    "* **Analyze** the code using profilers to identify bottlenecks and hotspots.\n",
    "* **Parallelize** the routines where most of the time in the code is spent.\n",
    "* **Optimize** the parallel code by analyzing first for opportunities, applying optimizations, verifying our gains, and repeating the process.\n",
    "\n",
    "### Metrics of Interest\n",
    "\n",
    "To quantify the performance gain, we denote the single-GPU execution time as $T_s$ and multi-GPU execution time for $P$ GPUs as $T_p$. Using this, we obtain the figures-of-merit:\n",
    "* Speedup $S = T_s/T_p$ (optimal is $P$), and \n",
    "* Efficiency $E = S/P$ (optimal is $1$). \n",
    "\n",
    "### Analyzing the code\n",
    "\n",
    "Let's profile the single-GPU code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9a8109",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../../source_code/single_gpu/ && nsys profile --trace=cuda,nvtx --stats=true -o jacobi_report --force-overwrite true ./jacobi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3c3c7",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now, download the report and view it via the GUI. This is the analysis step. Right click on the NVTX tab and select the Events View.\n",
    "\n",
    "![nsys single_gpu_analysis](../../images/nsys_single_gpu_analysis.png)\n",
    "\n",
    "Clearly, we need to parallelize the \"Jacobi Solve\" routine, which is essentially the iterative Jacobi solver loop. Click on the link to continue to the next lab where we parallelize the code using cudaMemcpy and CUDA streams:\n",
    "\n",
    "# [Multi-GPU: CUDA Streams](../memcpy/streams.ipynb)\n",
    "\n",
    "## Licensing \n",
    "\n",
    "This material is released by NVIDIA Corporation under the Creative Commons Attribution 4.0 International (CC BY 4.0). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
