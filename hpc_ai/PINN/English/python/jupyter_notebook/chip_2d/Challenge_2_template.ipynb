{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "Use PINNs to solve the parameterized fluid flow for the given geometry and flow parameters\n",
    "\n",
    "Simulate the same chip flow, but now with variable chip height and width in a single parameteric run. \n",
    "\n",
    "<img src=\"chip_2d_parameterized.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "## Challenge\n",
    "\n",
    "The main challenge in this problem is to correctly formulate the problem using PINNs. In order to achieve that, you will have to complete the following parts successfully:\n",
    "1. Define the correct *parameterized* geometry for the problem\n",
    "2. Set-up the correct boundary conditions and equations\n",
    "3. Create the neural network and solve the *parameteric* problem\n",
    "\n",
    "A successful completion of the problem should result a network that can be inferenced at any geometry parameter combination of our choice. For example, the model should be able to create plots for a geometry configuraions where the chip height is of 0.4 and width is 1.4. An example is shown below. Remember, once the model is trained, you can infer any geometry combination without the need to sovle the problem again. Quite cool isn't it!? \n",
    "\n",
    "<img src=\"challenge_results_param_updated.png\" alt=\"Drawing\" style=\"width: 800px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this template, we will have give you a skeleton code which you will fill in to define and solve the parametreric problem. If you have completed the challenge 1 successfully, moving to this part should be fairly easy as there are only a few minor edits. Let us start with importing the required packages.\n",
    "\n",
    "**Note: You need to edit the `chip_2d_parameterized_template.py` script that is placed in the ../source_code/chip_2d/ directory.**\n",
    "\n",
    "From the top menu, click on File, and Open `chip_2d_parameterized_template.py` from the current directory at `../source_code/chip_2d` directory. Remember to SAVE your code after changes, before running below cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from sympy import Symbol\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from modulus.solver import Solver\n",
    "from modulus.dataset import TrainDomain, ValidationDomain, InferenceDomain\n",
    "from modulus.data import Validation, Inference\n",
    "from modulus.sympy_utils.geometry_2d import Rectangle, Line, Channel2D\n",
    "from modulus.sympy_utils.functions import parabola\n",
    "from modulus.csv_utils.csv_rw import csv_to_dict\n",
    "from modulus.PDES.navier_stokes import IntegralContinuity, NavierStokes\n",
    "from modulus.controller import ModulusController\n",
    "from modulus.architecture import FourierNetArch\n",
    "from modulus.learning_rate import ExponentialDecayLRWithWarmup\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have defined the simulation parameters and the symbolic variables to parameterize the geometry below. As seen in the earlier tutorials, we have define a range in which data points will be sampled during the trainig. Feel free to try different ranges for the variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# simulation params\n",
    "channel_length = (-2.5, 2.5)\n",
    "channel_width = (-0.5, 0.5)\n",
    "chip_pos = -1.0\n",
    "#chip_height = 0.6         # Not fixed anymore\n",
    "#chip_width = 1.0          # Not fixed anymore\n",
    "inlet_vel = 1.5\n",
    "\n",
    "# paramteric variables\n",
    "chip_height = Symbol('chip_height')\n",
    "chip_width = Symbol('chip_width')\n",
    "\n",
    "chip_height_range = (0.4, 0.8)\n",
    "chip_width_range  = (0.6, 1.4)\n",
    "\n",
    "param_ranges = {chip_height: chip_height_range, \n",
    "                chip_width: chip_width_range}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#TODO: Replace all the placeholders with appropriate geometry constructions\n",
    "# define geometry here\n",
    "# you may use the geometry generated in the previous challenge problem as a reference\n",
    "\n",
    "channel = placeholder\n",
    "# define inlet and outlet\n",
    "inlet = placeholder\n",
    "outlet = placeholder\n",
    "# define the chip\n",
    "rec = placeholder\n",
    "# create a geometry for higher sampling of point cloud near the fin\n",
    "flow_rec = placeholder\n",
    "\n",
    "# fluid area\n",
    "geo = placeholder\n",
    "geo_hr = placeholder\n",
    "geo_lr = placeholder\n",
    "\n",
    "x_pos = Symbol('x_pos')\n",
    "integral_line = placeholder\n",
    "x_pos_range = {x_pos: lambda batch_size: np.full((batch_size, 1), np.random.uniform(channel_length[0], channel_length[1]))}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now complete the `Chip2DTrain` class below. Remember that this time, you will have to add the dictionary of the parameter keys and their ranges as an input to the `param_ranges` parameter. An example of the inlet boundary condition is already shown. *Note: For the integral continuity planes, you have two dictionaries. One for the randomly sampled* `x_pos` *and the other for the parameteric variables itself. Make sure to include both of these as input to the* `param_ranges`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#TODO: Replace all the placeholders with appropriate values \n",
    "\n",
    "# define sympy variables to parametrize domain curves\n",
    "x, y = Symbol('x'), Symbol('y')\n",
    "\n",
    "class Chip2DTrain(TrainDomain):\n",
    "  def __init__(self, **config):\n",
    "    super(Chip2DTrain, self).__init__()\n",
    "\n",
    "    # inlet\n",
    "    inlet_parabola = parabola(y, channel_width[0], channel_width[1], inlet_vel)\n",
    "    inlet_bc = inlet.boundary_bc(outvar_sympy={'u': inlet_parabola, 'v': 0},\n",
    "                                 batch_size_per_area=64,\n",
    "                                 param_ranges=param_ranges)\n",
    "    self.add(inlet_bc, name=\"Inlet\")\n",
    "\n",
    "    # outlet\n",
    "    outlet_bc = outlet.boundary_bc(outvar_sympy={placeholder},\n",
    "                                   batch_size_per_area=placeholder,\n",
    "                                   param_ranges=placeholder)\n",
    "    self.add(outlet_bc, name=\"Outlet\")\n",
    "\n",
    "    # noslip\n",
    "    noslip = geo.boundary_bc(outvar_sympy={placeholder},\n",
    "                             batch_size_per_area=placeholder,\n",
    "                             param_ranges=placeholder)\n",
    "    self.add(noslip, name=\"ChipNS\")\n",
    "\n",
    "    # interior lr\n",
    "    interior_lr = geo_lr.interior_bc(outvar_sympy={placeholder},\n",
    "                                     bounds={placeholder},\n",
    "                                     lambda_sympy={placeholder},\n",
    "                                     batch_size_per_area=placeholder,\n",
    "                                     param_ranges=placeholder)\n",
    "    self.add(interior_lr, name=\"InteriorLR\")\n",
    "\n",
    "    # interior hr\n",
    "    interior_hr = geo_hr.interior_bc(outvar_sympy={placeholder},\n",
    "                                     bounds={placeholder},\n",
    "                                     lambda_sympy={placeholder},\n",
    "                                     batch_size_per_area=placeholder,\n",
    "                                     param_ranges=placeholder)\n",
    "    self.add(interior_hr, name=\"InteriorHR\")\n",
    "\n",
    "\n",
    "    # integral continuity\n",
    "    for i in range(4):\n",
    "      IC = integral_line.boundary_bc(outvar_sympy={placeholder},\n",
    "                                     batch_size_per_area=placeholder,\n",
    "                                     lambda_sympy={placeholder},\n",
    "                                     criteria=placeholder,\n",
    "                                     param_ranges={placeholder},\n",
    "                                     fixed_var=placeholder)\n",
    "      self.add(IC, name=\"IntegralContinuity_\"+str(i))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, add validation data to the problem. Similar to the tutorial examples, validate this parameteric solution for a single configuration. Remember that the network for this problem has four inputs (x, y, chip_height, and chip_width). So your validation data also must have those corresponding inputs for each point in the CSV file. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# validation data\n",
    "mapping = {'Points:0': 'x', 'Points:1': 'y',\n",
    "           'U:0': 'u', 'U:1': 'v', 'p': 'p'}\n",
    "openfoam_var = csv_to_dict('openfoam/2D_chip_fluid0.csv', mapping)\n",
    "openfoam_var['x'] -= 2.5 # normalize pos\n",
    "openfoam_var['y'] -= 0.5\n",
    "\n",
    "#TODO: Add the arrays for 'chip_height' and 'chip_width'\n",
    "\n",
    "openfoam_invar_numpy = {key: value for key, value in openfoam_var.items() if key in ['x', 'y', 'chip_height', 'chip_width']}\n",
    "openfoam_outvar_numpy = {key: value for key, value in openfoam_var.items() if key in ['u', 'v', 'p']}\n",
    "\n",
    "class Chip2DVal(ValidationDomain):\n",
    "  def __init__(self, **config):\n",
    "    super(Chip2DVal, self).__init__()\n",
    "    val = Validation.from_numpy(openfoam_invar_numpy, openfoam_outvar_numpy)\n",
    "    self.add(val, name='Val')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed in the begining, we would like to visualize multiple designs without traing again and again. Let's define a `InferenceDomain` to do this. By changing the values in the this domain alone, and executing the script with `--run_mode=eval` commandline argument will help you to visualize multiple designs using the already trained network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Chip2DInf(InferenceDomain):\n",
    "  def __init__(self, **config):\n",
    "    super(Chip2DInf, self).__init__()\n",
    "    inf = Inference(geo.sample_interior(2048, bounds={x: channel_length, y: channel_width}, \n",
    "                                        param_ranges={chip_height: 0.4, chip_width: 1.4}),\n",
    "                    ['u', 'v', 'p'])\n",
    "    self.add(inf, name='Inference')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now finish the problem by defining the `ChipSolver` to solve our parametric problem. We have used the same fourier networks we used in the previous template. The important parameters of the neural network are defined for you. Feel free to tweak them and observe its behavior on the results and speed of convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#TODO: Replace all the placeholders with appropriate values\n",
    "class ChipSolver(Solver):\n",
    "  train_domain = placeholder\n",
    "  val_domain = placeholder\n",
    "  arch = FourierNetArch\n",
    "  lr = ExponentialDecayLRWithWarmup\n",
    "  inference_domain = placeholder\n",
    "\n",
    "  def __init__(self, **config):\n",
    "    super(ChipSolver, self).__init__(**config)\n",
    "\n",
    "    self.frequencies = ('axis,diagonal', [i/5. for i in range(25)]) \n",
    "\n",
    "    self.equations = (placeholder)\n",
    "    flow_net = self.arch.make_node(name='flow_net',\n",
    "                                   inputs=[placeholder],\n",
    "                                   outputs=[placeholder])\n",
    "    self.nets = [flow_net]\n",
    "\n",
    "  @classmethod\n",
    "  def update_defaults(cls, defaults):\n",
    "    defaults.update({\n",
    "        'network_dir': './network_checkpoint_chip_2d_parameterized',\n",
    "        'rec_results': True,\n",
    "        'rec_results_freq': 5000,\n",
    "        'max_steps': 20000,\n",
    "        'decay_steps': 400,\n",
    "        'warmup_type': 'gradual',\n",
    "        'warmup_steps': 2000,\n",
    "        'xla': True\n",
    "        })\n",
    "if __name__ == '__main__':\n",
    "  ctr = ModulusController(ChipSolver)\n",
    "  ctr.run()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Multi-GPU speedup\n",
    "\n",
    "Nvida Modulus library is optimized to achieve fast and scalable performance with features like accelerated linear algebra (XLA), automatic mixed precision (AMP) support and multi-GPU/multi-node implementation. You would have already observed that we had the `'xla'` option set to `True` for most of our examples. Here, we will discuss about the multi-GPU capabilies. For a detailed discussion on the performance upgrades available in Modulus, please refer to the *Modulus User Guide Chapter 16: Case Study: Performance Upgrades and Parallel Processing using Multi-GPU Configurations*\n",
    "\n",
    "To boost performance and to run larger problems, Modulus supports multi-GPU and multi-node scaling using Horovod. This allows for multiple processes, each targeting a single GPU, to perform independent forward and backward passes and aggregate the gradients collectively before updating the model weights. The figure below shows the scaling performance\n",
    "of Modulus on a annular ring test problem up to 128 V100 GPUs on 16 nodes. The scaling efficiency from 1 to 32 GPUs is more than 95%.\n",
    "<img src=\"multi_GPU_1.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "This data parallel fashion of multi-GPU training keeps the number of points sampled per GPU constant while increasing\n",
    "the total effective batch size. We can use this to our advantage to increase the number of points sampled by increasing\n",
    "the number of GPUs allowing us to handle much larger problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run the same scripts using multi-GPU to achieve larger batch sizes. And doing so, the time per iteration remains fairly constant and the benefits are mostly in terms of large problem solution (refer the figure above). But what if we want to also achieve faster time to convergence? If you noticed carefully, we have used a different learning rate schedule in this problem. This basically allows us to decrease the total time to convergence when training using multiple GPUs. This is done by scaling the learning rate linearly with the number of GPUs. As described in this [paper](https://arxiv.org/abs/1706.02677), simply increasing the learning rate can cause the model to diverge at large batch\n",
    "sizes. This can be fixed by using an initial learning rate warm-up. In this code we have made use of this feature of Modulus (with gradual warm-up). Below figure shows the learning rate schedule and the loss function evolution as the number of GPUs is increased from 1 to 16 for the NVSwitch heatsink case. For the multi-GPU cases, the learning rate is gradually increased from the baseline case and this allows the model to train without diverging early on and allows the model to converge faster as a result of the increased global batch size coupled with the increased learning rate.\n",
    "\n",
    "<img src=\"multi_GPU_2.png\" alt=\"Drawing\" style=\"width: 800px;\"/>\n",
    "\n",
    "For more details, refer to *Modulus User Guide Chapter 1 and Chapter 16*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run your code using multiple GPUs, simply execute the python script using the horovod command as follows\n",
    "\n",
    "`horovodrun -np #GPUs python_script.py `\n",
    "\n",
    "\n",
    "# Licensing\n",
    "This material is released by NVIDIA Corporation under the Creative Commons Attribution 4.0 International (CC BY 4.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
